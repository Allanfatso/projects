
# SpoolDir Configurations
spooldir configurations
name=smart-meter-consumption-source
connector.class=com.github.jcustenborder.kafka.connect.spooldir.SpoolDirCsvSourceConnector
topic=smart-meter-consumption
input.path=/home/confluent/data/unprocessed
input.file.pattern=.*\.csv
error.path=/home/confluent/data/error
finished.path=/home/confluent/data/processed
halt.on.error=false
csv.first.row.as.header=true
schema.generation.enabled=true
empty.poll.wait.ms=5000

# Explicitly define timestamp format
csv.datetime.parser.date.time.pattern=yyyy-MM-dd HH:mm:ss


# JDBC configurations
name=smart-meter-jdbc-sink
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
tasks.max=1
topics=smart-meter-consumption
connection.url=jdbc:postgresql://172.25.240.1:5432/postgres
connection.user=postgres
connection.password=password
auto.create=false
auto.evolve=false
insert.mode=insert
pk.mode=none
transforms=timestampCast,Cast

transforms.timestampCast.type=org.apache.kafka.connect.transforms.TimestampConverter$Value
transforms.timestampCast.field=Date_Time
transforms.timestampCast.target.type=Timestamp
transforms.timestampCast.format=yyyy-MM-dd HH:mm:ss

table.name.format=staging_consumption_data

transforms.Cast.type=org.apache.kafka.connect.transforms.Cast$Value
transforms.Cast.spec=KWHperHR:float64

quote.sql.identifiers=never
errors.tolerance=all
errors.log.enable=true
errors.log.include.messages=true
errors.deadletterqueue.topic.name=failed-records
errors.deadletterqueue.context.headers.enable=true





